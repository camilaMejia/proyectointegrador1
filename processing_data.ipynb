{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/cmejia3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/cmejia3/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/cmejia3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(['punkt','stopwords','wordnet'])\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import *\n",
    "from nltk.corpus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path =  Path(\"~\").expanduser().resolve()\n",
    "#base_path = Path.cwd().expanduser().resolve()\n",
    "input_file_path  = base_path / 'datasets/salidas/'\n",
    "datasetOut =base_path / \"datasets/salidas_procesamiento/\"\n",
    "datasetOut_freq = base_path / \"datasets/salidas_freq/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/cmejia3/datasets/salidas')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_ratio(input):\n",
    "    lang_ratio = {}\n",
    "    tokens = wordpunct_tokenize(input)\n",
    "    words = [word.lower() for word in tokens]\n",
    "    for language in stopwords.fileids():\n",
    "        stopwords_set = set(stopwords.words(language))\n",
    "        word_set = set(words)\n",
    "        common_elements = word_set.intersection(stopwords_set)\n",
    "        lang_ratio[language] = len(common_elements)\n",
    "    return lang_ratio\n",
    "\n",
    "def detect_language(input):\n",
    "    ratios = lang_ratio(input)\n",
    "    language = max(ratios, key = ratios.get)\n",
    "    return language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conjunto de las stop words que serán eliminadas ya que no aportan valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palabras que considermos StopWords que no estan incluidas en el conjunto descargado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "listoStopWords = ['www','https','html','figure', 'chapter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se añaden las palabras que consideramos al conjunto principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords.extend(listoStopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_files(texto,stopWords):\n",
    "    \n",
    "    #Quitar todos los acentos\n",
    "    #texto = unidecode.unidecode(texto)\n",
    "    \n",
    "    #Quitar todos los caracteres especiales\n",
    "    texto = re.sub('[^A-Za-z0-9]+',' ',texto)\n",
    "    \n",
    "    #Pasar todo a minisculas\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    #Tokenizar\n",
    "    tokens = texto.split()\n",
    "    \n",
    "    #Variable que guarda el año en el que estamos que es el limite superior de los números que no se van a eliminar\n",
    "    currentYear = int(dt.datetime.now().year)\n",
    "    \n",
    "    #Verificar que las palabras tengan más de un caracter, que además sean solo sean letras\n",
    "    # o si son números que esten entre un rango que sea admisible para no eliminar información de año que se mencione en los artículos\n",
    "    # y finalmente que no sean palabras que estan en el dicccionario de stopwords.\n",
    "    \n",
    "    tokens = [w for w in tokens if (len(w)>1)&(w.isalpha() or (w.isnumeric() and int(w)>=1800 and int(w)<=currentYear))&(w not in stopWords)]\n",
    "    \n",
    "    #Stemmer\n",
    "    ps = PorterStemmer() \n",
    "    tokens = [ps.stem(w) for w in tokens]\n",
    "    \n",
    "    #Lematización\n",
    "    word_net_lemmatizar = WordNetLemmatizer()\n",
    "\n",
    "    tokens = [word_net_lemmatizar.lemmatize(w, pos = \"v\") for w in tokens]\n",
    "    \n",
    "    #Se retorna el texto nuevamente en un solo string luego de ser procesado\n",
    "    to_return = ' '.join(tokens)\n",
    "    \n",
    "    #Se retorna el vocabulario de cada documento\n",
    "    set_words = set(tokens)\n",
    "    \n",
    "    #Y la frecuencia de las palabras\n",
    "    freq = nltk.FreqDist(tokens)\n",
    "    return to_return,set_words,freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def saving_freq(fd,fileOut,cant):\n",
    "    file = csv.writer(open(fileOut, 'w'))\n",
    "    for key, count in fd.most_common(cant):\n",
    "        file.writerow([key, count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialización de los conjuntos:\n",
    "\n",
    "    - Vocabulary: el conjunto de todas las palabras que contienen los documentos\n",
    "    - results_text: la lista con los documentos ya organizados para construir el bag of words\n",
    "    - results_frecuency: información de cada documento de las palabras que contiene cuántas veces las contiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set()\n",
    "results_text = []\n",
    "results_frecuency = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german:/home/cmejia3/datasets/salidas/1508.02340.txt\n"
     ]
    }
   ],
   "source": [
    "indexFiles = []\n",
    "for f in input_file_path.glob('*.txt'):\n",
    "#for f in docs_to_process['FileName']:\n",
    "    input_file = open(f, \"r\", encoding = 'utf-8')\n",
    "    texto = input_file.read()\n",
    "    aux = detect_language(texto)\n",
    "    if(aux == 'english'):\n",
    "        text_cleanned,set_words,freq = clean_files(texto,stopWords)\n",
    "        name_freq = str(f).split('/')[-1].split('.')[0] + '_freq.csv'\n",
    "        path_freq = datasetOut_freq / name_freq\n",
    "        saving_freq(freq,path_freq,50)\n",
    "        out2 = datasetOut / str(f).split('/')[-1]\n",
    "        outputFile2= open(out2, 'w', encoding='UTF-8')\n",
    "        outputFile2.write(text_cleanned)\n",
    "        outputFile2.close()\n",
    "        vocabulary = vocabulary.union(set_words)\n",
    "        results_text.append(text_cleanned)\n",
    "        #results_frecuency.append(freq)\n",
    "        indexFiles.append(str(out2))\n",
    "    else:\n",
    "        print(aux + ':' + str(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87073"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import vstack,save_npz,load_npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construido el vocabulario podemos construir el bag of words, que se hace con la ayuda de la funcion CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",vocabulary =vocabulary , tokenizer = None, preprocessor = None, stop_words = 'english', max_features = 5000) \n",
    "#train_data_features = vectorizer.fit_transform(results_text)\n",
    "#vectorizer.transform([\"Machine learning is great\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open(indexFiles[0], \"r\", encoding = 'utf-8')\n",
    "texto = input_file.read()\n",
    "train_data_features = vectorizer.fit_transform([texto])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,len(indexFiles)):\n",
    "    input_file = open(indexFiles[i], \"r\", encoding = 'utf-8')\n",
    "    texto = input_file.read()\n",
    "    aux = vectorizer.fit_transform([texto])\n",
    "    train_data_features = vstack((train_data_features, aux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz('sparse_matrix.npz', train_data_features)\n",
    "#sparse_matrix = load_npz('sparse_matrix.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'aa': 1,\n",
       " 'aaa': 2,\n",
       " 'aaaa': 3,\n",
       " 'aaaaa': 4,\n",
       " 'aaaaaa': 5,\n",
       " 'aaaaaaa': 6,\n",
       " 'aaaaaaaaaaaaaaaababa': 7,\n",
       " 'aaaab': 8,\n",
       " 'aaaababa': 9,\n",
       " 'aaab': 10,\n",
       " 'aaabbbbaaccccaaaacbbbcccbb': 11,\n",
       " 'aaai': 12,\n",
       " 'aaaiaaaipaperview': 13,\n",
       " 'aaaibarri': 14,\n",
       " 'aaaimit': 15,\n",
       " 'aaak': 16,\n",
       " 'aab': 17,\n",
       " 'aaba': 18,\n",
       " 'aabaabc': 19,\n",
       " 'aabab': 20,\n",
       " 'aababa': 21,\n",
       " 'aababaababb': 22,\n",
       " 'aabb': 23,\n",
       " 'aabbb': 24,\n",
       " 'aabc': 25,\n",
       " 'aabcdaccaac': 26,\n",
       " 'aabort': 27,\n",
       " 'aacccgctcgt': 28,\n",
       " 'aachen': 29,\n",
       " 'aacn': 30,\n",
       " 'aad': 31,\n",
       " 'aadbk': 32,\n",
       " 'aadom': 33,\n",
       " 'aaecc': 34,\n",
       " 'aaeccdoi': 35,\n",
       " 'aaem': 36,\n",
       " 'aaf': 37,\n",
       " 'aag': 38,\n",
       " 'aagaard': 39,\n",
       " 'aagea': 40,\n",
       " 'aah': 41,\n",
       " 'aai': 42,\n",
       " 'aaia': 43,\n",
       " 'aaihaa': 44,\n",
       " 'aain': 45,\n",
       " 'aaini': 46,\n",
       " 'aaixj': 47,\n",
       " 'aaj': 48,\n",
       " 'aajbb': 49,\n",
       " 'aak': 50,\n",
       " 'aakv': 51,\n",
       " 'aalbersberg': 52,\n",
       " 'aalborg': 53,\n",
       " 'aalg': 54,\n",
       " 'aall': 55,\n",
       " 'aalto': 56,\n",
       " 'aam': 57,\n",
       " 'aama': 58,\n",
       " 'aamarkov': 59,\n",
       " 'aamodt': 60,\n",
       " 'aan': 61,\n",
       " 'aana': 62,\n",
       " 'aanderaa': 63,\n",
       " 'aank': 64,\n",
       " 'aanstad': 65,\n",
       " 'aanund': 66,\n",
       " 'aar': 67,\n",
       " 'aarabi': 68,\n",
       " 'aardal': 69,\n",
       " 'aarhu': 70,\n",
       " 'aaron': 71,\n",
       " 'aaronson': 72,\n",
       " 'aarr': 73,\n",
       " 'aart': 74,\n",
       " 'aarti': 75,\n",
       " 'aas': 76,\n",
       " 'aashtiani': 77,\n",
       " 'aat': 78,\n",
       " 'aath': 79,\n",
       " 'aati': 80,\n",
       " 'aau': 81,\n",
       " 'aaw': 82,\n",
       " 'aawcondit': 83,\n",
       " 'aax': 84,\n",
       " 'aaxpi': 85,\n",
       " 'aazhang': 86,\n",
       " 'ab': 87,\n",
       " 'aba': 88,\n",
       " 'abaa': 89,\n",
       " 'abab': 90,\n",
       " 'ababa': 91,\n",
       " 'ababaaaaaaabaaaaabababaaaaab': 92,\n",
       " 'ababac': 93,\n",
       " 'ababb': 94,\n",
       " 'ababc': 95,\n",
       " 'ababp': 96,\n",
       " 'abac': 97,\n",
       " 'abacaxi': 98,\n",
       " 'abad': 99,\n",
       " 'abadi': 100,\n",
       " 'abaioff': 101,\n",
       " 'abaixo': 102,\n",
       " 'abak': 103,\n",
       " 'abalon': 104,\n",
       " 'abandon': 105,\n",
       " 'abaqu': 106,\n",
       " 'abaquscaestandard': 107,\n",
       " 'abarbanel': 108,\n",
       " 'abarbu': 109,\n",
       " 'abas': 110,\n",
       " 'abat': 111,\n",
       " 'abath': 112,\n",
       " 'abatzogl': 113,\n",
       " 'abb': 114,\n",
       " 'abba': 115,\n",
       " 'abbaa': 116,\n",
       " 'abbaac': 117,\n",
       " 'abbab': 118,\n",
       " 'abbadi': 119,\n",
       " 'abbasi': 120,\n",
       " 'abbasiyadkori': 121,\n",
       " 'abbass': 122,\n",
       " 'abbb': 123,\n",
       " 'abbbi': 124,\n",
       " 'abbcbccabcabcabcabcbcbabacba': 125,\n",
       " 'abbeel': 126,\n",
       " 'abbey': 127,\n",
       " 'abbildung': 128,\n",
       " 'abbo': 129,\n",
       " 'abbott': 130,\n",
       " 'abboud': 131,\n",
       " 'abbrevi': 132,\n",
       " 'abc': 133,\n",
       " 'abca': 134,\n",
       " 'abcab': 135,\n",
       " 'abcabbcabc': 136,\n",
       " 'abcabc': 137,\n",
       " 'abcabcp': 138,\n",
       " 'abcba': 139,\n",
       " 'abcd': 140,\n",
       " 'abcdefghijklmnopqrstuvwxyz': 141,\n",
       " 'abcdi': 142,\n",
       " 'abcedighfnljmqrpovustywxz': 143,\n",
       " 'abcp': 144,\n",
       " 'abcw': 145,\n",
       " 'abd': 146,\n",
       " 'abdallah': 147,\n",
       " 'abdceigfhjmlnqropstuvyzwx': 148,\n",
       " 'abdceigfhqropjm': 149,\n",
       " 'abdceigfhqropjmlnstuvyzwx': 150,\n",
       " 'abdeddam': 151,\n",
       " 'abdeg': 152,\n",
       " 'abdel': 153,\n",
       " 'abdelberi': 154,\n",
       " 'abdelgawad': 155,\n",
       " 'abdelhak': 156,\n",
       " 'abdelhakim': 157,\n",
       " 'abdelhaq': 158,\n",
       " 'abdelkad': 159,\n",
       " 'abdellatif': 160,\n",
       " 'abdelouahab': 161,\n",
       " 'abdelrahman': 162,\n",
       " 'abdelzah': 163,\n",
       " 'abderrahim': 164,\n",
       " 'abdesselam': 165,\n",
       " 'abdolali': 166,\n",
       " 'abdoulay': 167,\n",
       " 'abduc': 168,\n",
       " 'abduct': 169,\n",
       " 'abdul': 170,\n",
       " 'abdula': 171,\n",
       " 'abdulkadiroglu': 172,\n",
       " 'abdulla': 173,\n",
       " 'abdullah': 174,\n",
       " 'abdulrahman': 175,\n",
       " 'abdur': 176,\n",
       " 'abdx': 177,\n",
       " 'abe': 178,\n",
       " 'abel': 179,\n",
       " 'abela': 180,\n",
       " 'abelian': 181,\n",
       " 'abello': 182,\n",
       " 'abelson': 183,\n",
       " 'abep': 184,\n",
       " 'aber': 185,\n",
       " 'abercrombi': 186,\n",
       " 'aberg': 187,\n",
       " 'abernethi': 188,\n",
       " 'aberth': 189,\n",
       " 'aberystwyth': 190,\n",
       " 'abeyesingh': 191,\n",
       " 'abfp': 192,\n",
       " 'abgrenzung': 193,\n",
       " 'abgrp': 194,\n",
       " 'abh': 195,\n",
       " 'abhandlungen': 196,\n",
       " 'abhay': 197,\n",
       " 'abhaya': 198,\n",
       " 'abhi': 199,\n",
       " 'abhijeet': 200,\n",
       " 'abhijit': 201,\n",
       " 'abhik': 202,\n",
       " 'abhinav': 203,\n",
       " 'abhiruk': 204,\n",
       " 'abhishek': 205,\n",
       " 'abhradeep': 206,\n",
       " 'abhyankar': 207,\n",
       " 'abi': 208,\n",
       " 'abid': 209,\n",
       " 'abigail': 210,\n",
       " 'abigqropfhdjst': 211,\n",
       " 'abigqropfhdjstuvmyzwxlnc': 212,\n",
       " 'abigqrpohfcednljvustmywxz': 213,\n",
       " 'abii': 214,\n",
       " 'abil': 215,\n",
       " 'abilitytyp': 216,\n",
       " 'abingdon': 217,\n",
       " 'abiresearch': 218,\n",
       " 'abishanka': 219,\n",
       " 'abiteboul': 220,\n",
       " 'abiwt': 221,\n",
       " 'abj': 222,\n",
       " 'abjad': 223,\n",
       " 'abk': 224,\n",
       " 'abl': 225,\n",
       " 'ablat': 226,\n",
       " 'ablayev': 227,\n",
       " 'ablenot': 228,\n",
       " 'abley': 229,\n",
       " 'abli': 230,\n",
       " 'ablog': 231,\n",
       " 'abm': 232,\n",
       " 'abmash': 233,\n",
       " 'abmashdoc': 234,\n",
       " 'abn': 235,\n",
       " 'abnorm': 236,\n",
       " 'abnormalfaulti': 237,\n",
       " 'abolhasan': 238,\n",
       " 'abolish': 239,\n",
       " 'abon': 240,\n",
       " 'abor': 241,\n",
       " 'aboratori': 242,\n",
       " 'abordagem': 243,\n",
       " 'abort': 244,\n",
       " 'abortship': 245,\n",
       " 'abouelleil': 246,\n",
       " 'aboulnasr': 247,\n",
       " 'abound': 248,\n",
       " 'aboutorab': 249,\n",
       " 'aboutp': 250,\n",
       " 'aboutt': 251,\n",
       " 'abovebelow': 252,\n",
       " 'aboveclickablejqueri': 253,\n",
       " 'abovei': 254,\n",
       " 'abovement': 255,\n",
       " 'abovepdefinit': 256,\n",
       " 'abovepmean': 257,\n",
       " 'abovewhich': 258,\n",
       " 'abowd': 259,\n",
       " 'abox': 260,\n",
       " 'abp': 261,\n",
       " 'abpd': 262,\n",
       " 'abpl': 263,\n",
       " 'abpq': 264,\n",
       " 'abq': 265,\n",
       " 'abqp': 266,\n",
       " 'abr': 267,\n",
       " 'abraham': 268,\n",
       " 'abrahamson': 269,\n",
       " 'abram': 270,\n",
       " 'abramovich': 271,\n",
       " 'abramowitz': 272,\n",
       " 'abramski': 273,\n",
       " 'abramson': 274,\n",
       " 'abrego': 275,\n",
       " 'abreu': 276,\n",
       " 'abrial': 277,\n",
       " 'abridg': 278,\n",
       " 'abril': 279,\n",
       " 'abroad': 280,\n",
       " 'abrupt': 281,\n",
       " 'abruptli': 282,\n",
       " 'abrusci': 283,\n",
       " 'abrutyn': 284,\n",
       " 'abruzzi': 285,\n",
       " 'abs': 286,\n",
       " 'absastro': 287,\n",
       " 'absb': 288,\n",
       " 'absc': 289,\n",
       " 'abschatzungen': 290,\n",
       " 'abscissa': 291,\n",
       " 'abscoeff': 292,\n",
       " 'abscond': 293,\n",
       " 'absenc': 294,\n",
       " 'absent': 295,\n",
       " 'absentthes': 296,\n",
       " 'absi': 297,\n",
       " 'absil': 298,\n",
       " 'absmathmg': 299,\n",
       " 'absolut': 300,\n",
       " 'absolutecw': 301,\n",
       " 'absoluteleximin': 302,\n",
       " 'absolutelyrel': 303,\n",
       " 'absoluterel': 304,\n",
       " 'absorb': 305,\n",
       " 'absorpt': 306,\n",
       " 'absp': 307,\n",
       " 'absquant': 308,\n",
       " 'abstent': 309,\n",
       " 'abstract': 310,\n",
       " 'abstracta': 311,\n",
       " 'abstractaccur': 312,\n",
       " 'abstractalthough': 313,\n",
       " 'abstractanomali': 314,\n",
       " 'abstractapproxim': 315,\n",
       " 'abstractchaot': 316,\n",
       " 'abstractcomplex': 317,\n",
       " 'abstractdesign': 318,\n",
       " 'abstractdetect': 319,\n",
       " 'abstractdifferenti': 320,\n",
       " 'abstractdu': 321,\n",
       " 'abstractemot': 322,\n",
       " 'abstractergod': 323,\n",
       " 'abstractestim': 324,\n",
       " 'abstractfollow': 325,\n",
       " 'abstractfrequ': 326,\n",
       " 'abstractgiven': 327,\n",
       " 'abstractin': 328,\n",
       " 'abstractinformationcontrolcr': 329,\n",
       " 'abstractioninform': 330,\n",
       " 'abstractionrefin': 331,\n",
       " 'abstractit': 332,\n",
       " 'abstractli': 333,\n",
       " 'abstractlinkedlist': 334,\n",
       " 'abstractlinkedlistinit': 335,\n",
       " 'abstractlinkedlistisequalvalu': 336,\n",
       " 'abstractloc': 337,\n",
       " 'abstractmanga': 338,\n",
       " 'abstractmani': 339,\n",
       " 'abstractmodern': 340,\n",
       " 'abstractmodular': 341,\n",
       " 'abstractmotiv': 342,\n",
       " 'abstractmulti': 343,\n",
       " 'abstractnetwork': 344,\n",
       " 'abstractneur': 345,\n",
       " 'abstractnumer': 346,\n",
       " 'abstractorderedmapdecoratorabstractorderedmapdecor': 347,\n",
       " 'abstractpast': 348,\n",
       " 'abstractpatch': 349,\n",
       " 'abstractposit': 350,\n",
       " 'abstractprovid': 351,\n",
       " 'abstractscholarli': 352,\n",
       " 'abstractsearch': 353,\n",
       " 'abstractsensor': 354,\n",
       " 'abstractsequenti': 355,\n",
       " 'abstractsimplici': 356,\n",
       " 'abstractsimultan': 357,\n",
       " 'abstractspars': 358,\n",
       " 'abstractst': 359,\n",
       " 'abstractstealthi': 360,\n",
       " 'abstractth': 361,\n",
       " 'abstractther': 362,\n",
       " 'abstractthi': 363,\n",
       " 'abstracttoward': 364,\n",
       " 'abstracttwo': 365,\n",
       " 'abstractvehicl': 366,\n",
       " 'abstractw': 367,\n",
       " 'abstractwith': 368,\n",
       " 'abstrus': 369,\n",
       " 'absurd': 370,\n",
       " 'absurdo': 371,\n",
       " 'absurdum': 372,\n",
       " 'absv': 373,\n",
       " 'absw': 374,\n",
       " 'absz': 375,\n",
       " 'abt': 376,\n",
       " 'abtahi': 377,\n",
       " 'abu': 378,\n",
       " 'abualrub': 379,\n",
       " 'abubakr': 380,\n",
       " 'abugida': 381,\n",
       " 'abujarad': 382,\n",
       " 'abund': 383,\n",
       " 'abundanceecosystem': 384,\n",
       " 'abundanceproject': 385,\n",
       " 'abundantli': 386,\n",
       " 'abuot': 387,\n",
       " 'abur': 388,\n",
       " 'abus': 389,\n",
       " 'abuseof': 390,\n",
       " 'abut': 391,\n",
       " 'abuv': 392,\n",
       " 'abuz': 393,\n",
       " 'abuzaid': 394,\n",
       " 'abv': 395,\n",
       " 'abw': 396,\n",
       " 'abx': 397,\n",
       " 'abxi': 398,\n",
       " 'abxt': 399,\n",
       " 'abya': 400,\n",
       " 'abz': 401,\n",
       " 'ac': 402,\n",
       " 'aca': 403,\n",
       " 'acad': 404,\n",
       " 'academ': 405,\n",
       " 'academi': 406,\n",
       " 'academia': 407,\n",
       " 'academiaedu': 408,\n",
       " 'academiai': 409,\n",
       " 'academician': 410,\n",
       " 'academicplenum': 411,\n",
       " 'acadmi': 412,\n",
       " 'acadsci': 413,\n",
       " 'acal': 414,\n",
       " 'acampora': 415,\n",
       " 'acant': 416,\n",
       " 'acapulco': 417,\n",
       " 'acar': 418,\n",
       " 'acarchau': 419,\n",
       " 'acasteigtsjbotsim': 420,\n",
       " 'acaus': 421,\n",
       " 'acb': 422,\n",
       " 'acbab': 423,\n",
       " 'acbc': 424,\n",
       " 'acbct': 425,\n",
       " 'acbd': 426,\n",
       " 'acbt': 427,\n",
       " 'acc': 428,\n",
       " 'accademia': 429,\n",
       " 'accardi': 430,\n",
       " 'accdf': 431,\n",
       " 'accdg': 432,\n",
       " 'accdhyp': 433,\n",
       " 'accdm': 434,\n",
       " 'accel': 435,\n",
       " 'acceler': 436,\n",
       " 'acceleratedparallel': 437,\n",
       " 'acceleratorjsp': 438,\n",
       " 'acceleromet': 439,\n",
       " 'accent': 440,\n",
       " 'accentu': 441,\n",
       " 'accentur': 442,\n",
       " 'accept': 443,\n",
       " 'acceptancereject': 444,\n",
       " 'acceptingfin': 445,\n",
       " 'acceptk': 446,\n",
       " 'acceptor': 447,\n",
       " 'acceptreject': 448,\n",
       " 'acceptsrejectsrestart': 449,\n",
       " 'acces': 450,\n",
       " 'access': 451,\n",
       " 'accesscognit': 452,\n",
       " 'accessedmodifi': 453,\n",
       " 'accessiblilti': 454,\n",
       " 'accessor': 455,\n",
       " 'accessori': 456,\n",
       " 'accf': 457,\n",
       " 'accg': 458,\n",
       " 'accghyp': 459,\n",
       " 'acchyp': 460,\n",
       " 'acci': 461,\n",
       " 'accid': 462,\n",
       " 'accident': 463,\n",
       " 'accl': 464,\n",
       " 'acclaim': 465,\n",
       " 'accm': 466,\n",
       " 'accn': 467,\n",
       " 'acco': 468,\n",
       " 'accomazzi': 469,\n",
       " 'accommod': 470,\n",
       " 'accomod': 471,\n",
       " 'accompani': 472,\n",
       " 'accomplic': 473,\n",
       " 'accomplish': 474,\n",
       " 'acconnectedsubset': 475,\n",
       " 'accor': 476,\n",
       " 'accord': 477,\n",
       " 'accordi': 478,\n",
       " 'accordingli': 479,\n",
       " 'account': 480,\n",
       " 'accounthtml': 481,\n",
       " 'accountident': 482,\n",
       " 'accountmanag': 483,\n",
       " 'accountmanagerservic': 484,\n",
       " 'accountsindexhtml': 485,\n",
       " 'accoust': 486,\n",
       " 'accratef': 487,\n",
       " 'accratefhyp': 488,\n",
       " 'accrateg': 489,\n",
       " 'accrateghyp': 490,\n",
       " 'accratem': 491,\n",
       " 'accrel': 492,\n",
       " 'accru': 493,\n",
       " 'acct': 494,\n",
       " 'accuari': 495,\n",
       " 'accumul': 496,\n",
       " 'accur': 497,\n",
       " 'accuraci': 498,\n",
       " 'accuraciesf': 499,\n",
       " 'accuracyf': 500,\n",
       " 'accuracyfscor': 501,\n",
       " 'accuracyit': 502,\n",
       " 'accuracymemori': 503,\n",
       " 'accuracyp': 504,\n",
       " 'accuracyprecis': 505,\n",
       " 'accuracysolut': 506,\n",
       " 'accuracyth': 507,\n",
       " 'accuracyther': 508,\n",
       " 'accus': 509,\n",
       " 'accv': 510,\n",
       " 'accx': 511,\n",
       " 'acd': 512,\n",
       " 'acda': 513,\n",
       " 'acdar': 514,\n",
       " 'acdau': 515,\n",
       " 'acdb': 516,\n",
       " 'ace': 517,\n",
       " 'acea': 518,\n",
       " 'acebr': 519,\n",
       " 'acebron': 520,\n",
       " 'acecomplet': 521,\n",
       " 'acemoglu': 522,\n",
       " 'acentr': 523,\n",
       " 'acerbi': 524,\n",
       " 'acerca': 525,\n",
       " 'acero': 526,\n",
       " 'aceska': 527,\n",
       " 'aceto': 528,\n",
       " 'acevedo': 529,\n",
       " 'acf': 530,\n",
       " 'acfor': 531,\n",
       " 'acg': 532,\n",
       " 'acgilbert': 533,\n",
       " 'acgt': 534,\n",
       " 'ach': 535,\n",
       " 'achan': 536,\n",
       " 'achanta': 537,\n",
       " 'achar': 538,\n",
       " 'achara': 539,\n",
       " 'achari': 540,\n",
       " 'acharya': 541,\n",
       " 'acheiev': 542,\n",
       " 'achi': 543,\n",
       " 'achieiv': 544,\n",
       " 'achiev': 545,\n",
       " 'achievabil': 546,\n",
       " 'achievabiliy': 547,\n",
       " 'achievabl': 548,\n",
       " 'achievebl': 549,\n",
       " 'achievedpsfrag': 550,\n",
       " 'achil': 551,\n",
       " 'achillea': 552,\n",
       " 'achilleo': 553,\n",
       " 'achim': 554,\n",
       " 'achin': 555,\n",
       " 'achiv': 556,\n",
       " 'achliopta': 557,\n",
       " 'achrekar': 558,\n",
       " 'achterberg': 559,\n",
       " 'achtergracht': 560,\n",
       " 'aci': 561,\n",
       " 'acial': 562,\n",
       " 'acid': 563,\n",
       " 'acifar': 564,\n",
       " 'acij': 565,\n",
       " 'acin': 566,\n",
       " 'acit': 567,\n",
       " 'aciv': 568,\n",
       " 'acjp': 569,\n",
       " 'ack': 570,\n",
       " 'ackerman': 571,\n",
       " 'ackermann': 572,\n",
       " 'acket': 573,\n",
       " 'ackijk': 574,\n",
       " 'ackley': 575,\n",
       " 'acklm': 576,\n",
       " 'acknowledg': 577,\n",
       " 'acknowledgementsw': 578,\n",
       " 'acknowlegd': 579,\n",
       " 'ackoff': 580,\n",
       " 'ackowledg': 581,\n",
       " 'ackstrom': 582,\n",
       " 'ackt': 583,\n",
       " 'acl': 584,\n",
       " 'aclc': 585,\n",
       " 'aclcol': 586,\n",
       " 'aclf': 587,\n",
       " 'aclijcnlp': 588,\n",
       " 'aclremoveentri': 589,\n",
       " 'aclust': 590,\n",
       " 'acm': 591,\n",
       " 'acmicpc': 592,\n",
       " 'acmiee': 593,\n",
       " 'acmifipusenix': 594,\n",
       " 'acml': 595,\n",
       " 'acmmm': 596,\n",
       " 'acmsiam': 597,\n",
       " 'acmsigda': 598,\n",
       " 'acn': 599,\n",
       " 'acna': 600,\n",
       " 'acnc': 601,\n",
       " 'acnd': 602,\n",
       " 'aco': 603,\n",
       " 'acohido': 604,\n",
       " 'acolor': 605,\n",
       " 'acom': 606,\n",
       " 'acompi': 607,\n",
       " 'acomprehens': 608,\n",
       " 'acomput': 609,\n",
       " 'aconsist': 610,\n",
       " 'aconst': 611,\n",
       " 'acontrol': 612,\n",
       " 'acoord': 613,\n",
       " 'acopf': 614,\n",
       " 'acori': 615,\n",
       " 'acorrect': 616,\n",
       " 'acosd': 617,\n",
       " 'acosta': 618,\n",
       " 'acou': 619,\n",
       " 'acount': 620,\n",
       " 'acoust': 621,\n",
       " 'acp': 622,\n",
       " 'acpa': 623,\n",
       " 'acpj': 624,\n",
       " 'acq': 625,\n",
       " 'acqpa': 626,\n",
       " 'acquaint': 627,\n",
       " 'acquir': 628,\n",
       " 'acquisit': 629,\n",
       " 'acquisti': 630,\n",
       " 'acr': 631,\n",
       " 'acrf': 632,\n",
       " 'acri': 633,\n",
       " 'acro': 634,\n",
       " 'acrocel': 635,\n",
       " 'acronym': 636,\n",
       " 'across': 637,\n",
       " 'acrow': 638,\n",
       " 'acsac': 639,\n",
       " 'acsd': 640,\n",
       " 'acsm': 641,\n",
       " 'acssc': 642,\n",
       " 'acsysimp': 643,\n",
       " 'act': 644,\n",
       " 'acta': 645,\n",
       " 'acteris': 646,\n",
       " 'acti': 647,\n",
       " 'actin': 648,\n",
       " 'action': 649,\n",
       " 'actioncomedydrama': 650,\n",
       " 'actiondata': 651,\n",
       " 'actionev': 652,\n",
       " 'actionif': 653,\n",
       " 'actionlabel': 654,\n",
       " 'actionpageid': 655,\n",
       " 'actionpercept': 656,\n",
       " 'actionrecord': 657,\n",
       " 'actionsth': 658,\n",
       " 'actionstreat': 659,\n",
       " 'actiontreat': 660,\n",
       " 'activ': 661,\n",
       " 'activandrewcmueduuserbhooiratingstar': 662,\n",
       " 'activationbas': 663,\n",
       " 'activationdescactivationdesc': 664,\n",
       " 'activationgroup': 665,\n",
       " 'activationgroupcreategroup': 666,\n",
       " 'activationgroupinactiveobject': 667,\n",
       " 'activationinactiv': 668,\n",
       " 'activationsystem': 669,\n",
       " 'activeadapt': 670,\n",
       " 'activepass': 671,\n",
       " 'activereact': 672,\n",
       " 'activeset': 673,\n",
       " 'activis': 674,\n",
       " 'activist': 675,\n",
       " 'activit': 676,\n",
       " 'activityactonto': 677,\n",
       " 'activityaspect': 678,\n",
       " 'activityedg': 679,\n",
       " 'activityedgeaspect': 680,\n",
       " 'activityedgeimpl': 681,\n",
       " 'activityimpl': 682,\n",
       " 'activitynet': 683,\n",
       " 'activitynod': 684,\n",
       " 'activitynodeactivationgroup': 685,\n",
       " 'activitynodeaspect': 686,\n",
       " 'activitynodeimpl': 687,\n",
       " 'activityparameternod': 688,\n",
       " 'activityserviceproviderreceiv': 689,\n",
       " 'activitythat': 690,\n",
       " 'activityui': 691,\n",
       " 'activityx': 692,\n",
       " 'actno': 693,\n",
       " 'acton': 694,\n",
       " 'actonto': 695,\n",
       " 'actor': 696,\n",
       " 'actorbas': 697,\n",
       " 'actorbehavior': 698,\n",
       " 'actorcrit': 699,\n",
       " 'actorfor': 700,\n",
       " 'actorfoundri': 701,\n",
       " 'actorfoundrywhich': 702,\n",
       " 'actorpoint': 703,\n",
       " 'actorr': 704,\n",
       " 'actorreact': 705,\n",
       " 'actorref': 706,\n",
       " 'actorrepli': 707,\n",
       " 'actorsthousand': 708,\n",
       " 'actoutcom': 709,\n",
       " 'actpbq': 710,\n",
       " 'actpq': 711,\n",
       " 'actpqq': 712,\n",
       " 'actq': 713,\n",
       " 'actscr': 714,\n",
       " 'actsh': 715,\n",
       " 'actshr': 716,\n",
       " 'actsi': 717,\n",
       " 'actslo': 718,\n",
       " 'actt': 719,\n",
       " 'actu': 720,\n",
       " 'actual': 721,\n",
       " 'actualis': 722,\n",
       " 'actualment': 723,\n",
       " 'actuari': 724,\n",
       " 'actuat': 725,\n",
       " 'acu': 726,\n",
       " 'acukcjbimagesgfhtml': 727,\n",
       " 'acustica': 728,\n",
       " 'acut': 729,\n",
       " 'acvt': 730,\n",
       " 'acx': 731,\n",
       " 'acycl': 732,\n",
       " 'acyclicli': 733,\n",
       " 'acycloid': 734,\n",
       " 'acyl': 735,\n",
       " 'aczel': 736,\n",
       " 'ad': 737,\n",
       " 'ada': 738,\n",
       " 'adaba': 739,\n",
       " 'adaboost': 740,\n",
       " 'adachi': 741,\n",
       " 'adadelta': 742,\n",
       " 'adadi': 743,\n",
       " 'adag': 744,\n",
       " 'adak': 745,\n",
       " 'adalbert': 746,\n",
       " 'adalf': 747,\n",
       " 'adalfsdk': 748,\n",
       " 'adalfsdt': 749,\n",
       " 'adalsteinsson': 750,\n",
       " 'adam': 751,\n",
       " 'adamatzki': 752,\n",
       " 'adamczak': 753,\n",
       " 'adamek': 754,\n",
       " 'adami': 755,\n",
       " 'adamof': 756,\n",
       " 'adamsbashforth': 757,\n",
       " 'adamsbashforthmoulton': 758,\n",
       " 'adamson': 759,\n",
       " 'adao': 760,\n",
       " 'adap': 761,\n",
       " 'adapco': 762,\n",
       " 'adapcocom': 763,\n",
       " 'adapt': 764,\n",
       " 'adaptao': 765,\n",
       " 'adaptationcorrect': 766,\n",
       " 'adaptationgfk': 767,\n",
       " 'adaptivemax': 768,\n",
       " 'adaptivemean': 769,\n",
       " 'adaptiverobust': 770,\n",
       " 'adaptivesum': 771,\n",
       " 'adar': 772,\n",
       " 'adaricheva': 773,\n",
       " 'adat': 774,\n",
       " 'adavani': 775,\n",
       " 'adbbb': 776,\n",
       " 'adc': 777,\n",
       " 'adcock': 778,\n",
       " 'adcol': 779,\n",
       " 'add': 780,\n",
       " 'addabbo': 781,\n",
       " 'addad': 782,\n",
       " 'addaiu': 783,\n",
       " 'addario': 784,\n",
       " 'addcandrul': 785,\n",
       " 'addcandrulesu': 786,\n",
       " 'addcandruleu': 787,\n",
       " 'addclocklisten': 788,\n",
       " 'adddit': 789,\n",
       " 'addednot': 790,\n",
       " 'addedremov': 791,\n",
       " 'addedsubtract': 792,\n",
       " 'addend': 793,\n",
       " 'addendum': 794,\n",
       " 'adder': 795,\n",
       " 'addet': 796,\n",
       " 'addflip': 797,\n",
       " 'addi': 798,\n",
       " 'addict': 799,\n",
       " 'addingremov': 800,\n",
       " 'addingsubtract': 801,\n",
       " 'addis': 802,\n",
       " 'addison': 803,\n",
       " 'addisonwesley': 804,\n",
       " 'addisson': 805,\n",
       " 'addit': 806,\n",
       " 'additio': 807,\n",
       " 'additiondelet': 808,\n",
       " 'additionfor': 809,\n",
       " 'additionn': 810,\n",
       " 'additionremov': 811,\n",
       " 'additiveacross': 812,\n",
       " 'additiveerror': 813,\n",
       " 'additiven': 814,\n",
       " 'additivepfor': 815,\n",
       " 'addiu': 816,\n",
       " 'addmax': 817,\n",
       " 'addmaxc': 818,\n",
       " 'addnod': 819,\n",
       " 'addon': 820,\n",
       " 'addorn': 821,\n",
       " 'addpositioningconstraint': 822,\n",
       " 'addpx': 823,\n",
       " 'addr': 824,\n",
       " 'addrandomappl': 825,\n",
       " 'address': 826,\n",
       " 'addresse': 827,\n",
       " 'addressedand': 828,\n",
       " 'addscor': 829,\n",
       " 'addscorei': 830,\n",
       " 'addtion': 831,\n",
       " 'addu': 832,\n",
       " 'adduc': 833,\n",
       " 'addx': 834,\n",
       " 'adec': 835,\n",
       " 'adecod': 836,\n",
       " 'adel': 837,\n",
       " 'adelaid': 838,\n",
       " 'adelgren': 839,\n",
       " 'adelin': 840,\n",
       " 'adelman': 841,\n",
       " 'adelmann': 842,\n",
       " 'adelson': 843,\n",
       " 'aden': 844,\n",
       " 'adenin': 845,\n",
       " 'adequ': 846,\n",
       " 'adequaci': 847,\n",
       " 'ader': 848,\n",
       " 'aderiv': 849,\n",
       " 'adesnik': 850,\n",
       " 'adesso': 851,\n",
       " 'adet': 852,\n",
       " 'adetermin': 853,\n",
       " 'adetunji': 854,\n",
       " 'adewol': 855,\n",
       " 'adford': 856,\n",
       " 'adfsdca': 857,\n",
       " 'adg': 858,\n",
       " 'adga': 859,\n",
       " 'adh': 860,\n",
       " 'adham': 861,\n",
       " 'adher': 862,\n",
       " 'adhes': 863,\n",
       " 'adhikari': 864,\n",
       " 'adhoc': 865,\n",
       " 'adhu': 866,\n",
       " 'adi': 867,\n",
       " 'adiabat': 868,\n",
       " 'adiac': 869,\n",
       " 'adibi': 870,\n",
       " 'adic': 871,\n",
       " 'adida': 872,\n",
       " 'adifor': 873,\n",
       " 'adigit': 874,\n",
       " 'adijac': 875,\n",
       " 'adijacautomat': 876,\n",
       " 'adilson': 877,\n",
       " 'adim': 878,\n",
       " 'adimat': 879,\n",
       " 'adio': 880,\n",
       " 'adipos': 881,\n",
       " 'adiqu': 882,\n",
       " 'adirect': 883,\n",
       " 'adish': 884,\n",
       " 'adist': 885,\n",
       " 'adistm': 886,\n",
       " 'adit': 887,\n",
       " 'aditya': 888,\n",
       " 'adiwena': 889,\n",
       " 'adj': 890,\n",
       " 'adjac': 891,\n",
       " 'adjacent': 892,\n",
       " 'adjacentclos': 893,\n",
       " 'adjacentclosur': 894,\n",
       " 'adjacentincid': 895,\n",
       " 'adject': 896,\n",
       " 'adjg': 897,\n",
       " 'adji': 898,\n",
       " 'adjnoun': 899,\n",
       " 'adjoin': 900,\n",
       " 'adjoint': 901,\n",
       " 'adjud': 902,\n",
       " 'adjug': 903,\n",
       " 'adjunct': 904,\n",
       " 'adjust': 905,\n",
       " 'adjustmenta': 906,\n",
       " 'adjustp': 907,\n",
       " 'adk': 908,\n",
       " 'adl': 909,\n",
       " 'adlakha': 910,\n",
       " 'adleman': 911,\n",
       " 'adler': 912,\n",
       " 'adma': 913,\n",
       " 'admetox': 914,\n",
       " 'admin': 915,\n",
       " 'administ': 916,\n",
       " 'administr': 917,\n",
       " 'admir': 918,\n",
       " 'admira': 919,\n",
       " 'admiss': 920,\n",
       " 'admissibleinadmiss': 921,\n",
       " 'admistr': 922,\n",
       " 'admit': 923,\n",
       " 'admitt': 924,\n",
       " 'admittedli': 925,\n",
       " 'admm': 926,\n",
       " 'adn': 927,\n",
       " 'adnot': 928,\n",
       " 'ado': 929,\n",
       " 'adob': 930,\n",
       " 'adol': 931,\n",
       " 'adolesc': 932,\n",
       " 'adolfo': 933,\n",
       " 'adom': 934,\n",
       " 'adomaviciu': 935,\n",
       " 'adomfi': 936,\n",
       " 'adomj': 937,\n",
       " 'adomq': 938,\n",
       " 'adopt': 939,\n",
       " 'adorn': 940,\n",
       " 'adp': 941,\n",
       " 'adpk': 942,\n",
       " 'adpoint': 943,\n",
       " 'adpt': 944,\n",
       " 'adptiv': 945,\n",
       " 'adq': 946,\n",
       " 'adr': 947,\n",
       " 'adress': 948,\n",
       " 'adresses': 949,\n",
       " 'adria': 950,\n",
       " 'adrian': 951,\n",
       " 'adriana': 952,\n",
       " 'adriano': 953,\n",
       " 'adrien': 954,\n",
       " 'adsaf': 955,\n",
       " 'adsolv': 956,\n",
       " 'adsorpt': 957,\n",
       " 'adt': 958,\n",
       " 'adtk': 959,\n",
       " 'adu': 960,\n",
       " 'adult': 961,\n",
       " 'adulthood': 962,\n",
       " 'adusumilli': 963,\n",
       " 'adv': 964,\n",
       " 'advanc': 965,\n",
       " 'advancefor': 966,\n",
       " 'advancepoint': 967,\n",
       " 'advancingfront': 968,\n",
       " 'advantag': 969,\n",
       " 'advcdh': 970,\n",
       " 'advclass': 971,\n",
       " 'advdummi': 972,\n",
       " 'advect': 973,\n",
       " 'advectivediffus': 974,\n",
       " 'advent': 975,\n",
       " 'adventur': 976,\n",
       " 'advers': 977,\n",
       " 'adversari': 978,\n",
       " 'adversariesit': 979,\n",
       " 'adversariesthey': 980,\n",
       " 'adversaryenviron': 981,\n",
       " 'adversarysimul': 982,\n",
       " 'advert': 983,\n",
       " 'advertis': 984,\n",
       " 'advertisejoin': 985,\n",
       " 'advf': 986,\n",
       " 'advic': 987,\n",
       " 'advicenbug': 988,\n",
       " 'advis': 989,\n",
       " 'advisor': 990,\n",
       " 'advisori': 991,\n",
       " 'advoc': 992,\n",
       " 'advocaci': 993,\n",
       " 'advol': 994,\n",
       " 'advz': 995,\n",
       " 'adwait': 996,\n",
       " 'adword': 997,\n",
       " 'adx': 998,\n",
       " 'adz': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocabulary.txt', 'w') as f:\n",
    "    for item in vectorizer.get_feature_names():\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'BoW1.sav'\n",
    "pickle.dump(vectorizer, open(filename, 'wb'))\n",
    "#loaded_model = pickle.load(open('BoW1.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 300)\t1\n",
      "  (0, 305)\t3\n",
      "  (0, 306)\t2\n",
      "  (0, 310)\t1\n",
      "  (0, 333)\t1\n",
      "  (0, 430)\t1\n",
      "  (0, 477)\t1\n",
      "  (0, 480)\t2\n",
      "  (0, 563)\t2\n",
      "  (0, 628)\t2\n",
      "  (0, 725)\t1\n",
      "  (0, 806)\t1\n",
      "  (0, 826)\t1\n",
      "  (0, 912)\t1\n",
      "  (0, 1997)\t1\n",
      "  (0, 2058)\t1\n",
      "  (0, 2101)\t1\n",
      "  (0, 2430)\t1\n",
      "  (0, 2696)\t1\n",
      "  (0, 2743)\t6\n",
      "  (0, 2876)\t1\n",
      "  (0, 3076)\t1\n",
      "  (0, 3105)\t1\n",
      "  (0, 3108)\t2\n",
      "  (0, 3164)\t2\n",
      "  :\t:\n",
      "  (978, 79743)\t1\n",
      "  (978, 79803)\t11\n",
      "  (978, 79982)\t1\n",
      "  (978, 80292)\t24\n",
      "  (978, 80335)\t1\n",
      "  (978, 80418)\t1\n",
      "  (978, 80422)\t11\n",
      "  (978, 80438)\t3\n",
      "  (978, 80708)\t1\n",
      "  (978, 80973)\t1\n",
      "  (978, 81000)\t1\n",
      "  (978, 81125)\t1\n",
      "  (978, 81285)\t1\n",
      "  (978, 82345)\t1\n",
      "  (978, 82397)\t3\n",
      "  (978, 82804)\t1\n",
      "  (978, 82885)\t1\n",
      "  (978, 83010)\t1\n",
      "  (978, 83308)\t5\n",
      "  (978, 83651)\t1\n",
      "  (978, 83694)\t1\n",
      "  (978, 83843)\t1\n",
      "  (978, 84533)\t2\n",
      "  (978, 85707)\t2\n",
      "  (978, 86467)\t1\n"
     ]
    }
   ],
   "source": [
    "print(train_data_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6(conda)",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
