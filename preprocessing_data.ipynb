{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando las librerías requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definiendo variables del entorno de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetIn =\"datasets/papers-txt/\"\n",
    "datasetOut =\"datasets/salida/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones para preprocesar los archivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileSize(path, pfile):\n",
    "    fileIn= path + pfile\n",
    "    size=os.stat(fileIn).st_size\n",
    "    return size\n",
    "\n",
    "def wordsCount(path, pfile):\n",
    "    fileIn= path + pfile\n",
    "    inputFile = open(fileIn, 'r', encoding='UTF-8')\n",
    "    contenido=inputFile.read()\n",
    "    inputFile.close()\n",
    "    #return Counter(map(str, contenido.split()))\n",
    "    totWwords=contenido.split()\n",
    "    return len(totWwords)\n",
    "\n",
    "def cleanWordCount(pathIn, pfile,pathOut):\n",
    "    fileIn= pathIn + pfile\n",
    "    fileOut =pathOut + pfile\n",
    "    inputFile = open(fileIn, 'r', encoding='UTF-8')\n",
    "    contenido=inputFile.read()\n",
    "    inputFile.close()\n",
    "    contenido =re.sub('(f|ht)tp(s?)://(.*)[.][a-z]+',' ',contenido) # Eliminar las URL\n",
    "    #contenido =re.sub('REFERENCES (\\S|\\w)+',' ',contenido) # Eliminar la bibliografia\n",
    "    contenido =re.sub('[a-zA-Z0-9.?{}]+@\\w+\\.\\w+.\\w*',' ',contenido) # Eliminar los correos\n",
    "    contenido =re.sub('\\[[a-zA-Z0-9\\,\\. ]+\\]',' ',contenido) # Eliminar cualquier contenido entre corchetes\n",
    "    contenido =re.sub('\\([a-zA-Z0-9\\,\\.\\- ]+\\)',' ',contenido) # Eliminar cualquier contenido entre paréntesis\n",
    "    contenido =re.sub('((et al\\.)|(i\\.i\\.d\\.)|(i\\.e\\.)|\\-|\\'|\\’|\\`)',' ',contenido) # Eliminar abreviaciones, apostrofes y guion\n",
    "    #contenido =re.sub('(f|F)igure [0-9]+.[0-9]',' ',contenido) # Eliminar Figure\n",
    "    contenido =re.sub('[^a-zA-Z_á\\éíóúà\\èìòùäëïöü\\s]','',contenido) # Eliminar caracteres que no sean: letra, número o vocales acentuadas\n",
    "    contenido =re.sub(' +',' ',contenido) # Eliminar espacios en blanco\n",
    "    contenido =re.sub('(a-z|A-Z){1,1}',' ',contenido) # Eliminar palabras o números de un caracter de longitud   \n",
    "    #contenido =re.sub('[^A-Za-z0-9.,_%+-\\(\\)\\[\\]\\´\\'\\`]',' ',contenido)\n",
    "    #contenido =re.sub('\\[(0-9)+\\]',' ',contenido)    \n",
    "    #totWordDepurado = Counter(map(str, contenido.split()))\n",
    "    outputFile= open(fileOut, 'w', encoding='UTF-8')\n",
    "    outputFile.write(contenido)\n",
    "    outputFile.close()\n",
    "    totWwords=contenido.split()\n",
    "    #print(\"Total de palabras {}\".format(len(totWwords)))\n",
    "    #print(\"Total de palabras después del pre-procesamiento: {}\".format(totWordDepurado))\n",
    "    return len(totWwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-procesamiento de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtfiles=os.listdir(datasetIn)\n",
    "numFiles=len(txtfiles)\n",
    "\n",
    "i=0\n",
    "fileSummary = datasetOut + \"CleanSummary.csv\"\n",
    "outputFile= open(fileSummary, 'w', encoding='UTF-8')\n",
    "contenido= \"Archivo\" + \";\" + \"Tamaño(K)\" + \";\" + \"Cant Palabras Inicial\" + \";\" + \"Cant Palabras depuradas\"+ \";\" +\"Porc Limpieza\"+ \"\\n\"\n",
    "while  (i < numFiles):\n",
    "    tempFile=txtfiles[i]\n",
    "    tmpSize=round(fileSize(datasetIn,tempFile)/1014)\n",
    "    tmpWordsOri=wordsCount(datasetIn,tempFile)\n",
    "    tmpWordsEnd=cleanWordCount(datasetIn,tempFile,datasetOut)\n",
    "    tmpPerClean=round((tmpWordsEnd/tmpWordsOri)*100)\n",
    "    contenido= tempFile + \";\" + str(tmpSize) + \";\" + str(tmpWordsOri) + \";\" + str(tmpWordsEnd)+ \";\" + str(tmpPerClean) + \"\\n\"\n",
    "    outputFile.write(contenido)\n",
    "    i=i+1\n",
    "\n",
    "outputFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
